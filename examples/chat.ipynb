{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32b169b3",
   "metadata": {},
   "source": [
    "# Chat Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5819fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Configure client to use local server\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:10240/v1\",  # Point to local server\n",
    "    api_key=\"not-needed\"  # API key is not required for local server\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3bafa8f",
   "metadata": {},
   "source": [
    "## v1/chat/completions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1349a27",
   "metadata": {},
   "source": [
    "You can directly test using the curl method, as follows:\n",
    "\n",
    "```shell\n",
    "curl http://localhost:10240/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"mlx-community/gemma-3-1b-it-4bit-DWQ\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello!\"\n",
    "      }\n",
    "    ]\n",
    "  }'\n",
    "\n",
    "```\n",
    "\n",
    "You can also use OpenAI's Python SDK in the project for access, which can basically be done without feeling. As follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280fe5e6-0c7f-4554-93a9-0d30cce21f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"mlx-community/gemma-3-1b-it-4bit-DWQ\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "539ec72e-a2ae-4abb-a485-6bbd8063bdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ac6138de1f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat for a bit?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732542634, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=28, prompt_tokens=3, total_tokens=31, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e65dbe4-da71-4b7f-a495-a9fbe292d47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='Hello!', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "Hello!\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=\" It's\", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " It's\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' nice', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " nice\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " to\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' meet', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " meet\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' you.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " you.\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' Is', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " Is\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' there', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " there\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' something', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " something\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " I\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " can\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " help\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " you\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' with,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " with,\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' or', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " or\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' would', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " would\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " you\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' like', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " like\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " to\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' chat', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " chat\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " for\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " a\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"mlx-community/gemma-3-1b-it-4bit-DWQ\",\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True  # this time, we set stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk)\n",
    "    print(chunk.choices[0].delta.content)\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b2d95",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "## Structured Output\n",
    "\n",
    "https://platform.openai.com/docs/guides/structured-outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e813dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"characters\": [\n",
      "    {\n",
      "      \"name\": \"Sidra Shafer\",\n",
      "      \"occupation\": \"Private Investigator\",\n",
      "      \"personality\": \"Incited and independent\",\n",
      "      \"background\": \"Former U.S. Army combat medic, Sidra lives in Savannah, Georgia. She has sharp instincts and a tenacious spirit that's driven her to risk everything to unravel the darkest mysteries of the Deep South.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Axel Laurie\",\n",
      "      \"occupation\": \"Science Writer\",\n",
      "      \"personality\": \" 'A globetrotting thrill-seeker, Axel seeks journalistic scoops that let him scurry into powers that be web', a hardened city boy's mindset statistically wired with logical common senses mixed well with reverence him with spicy vindictive sensibilities.\",\n",
      "      \"background\": \"Former dependent surveillance team consultant near Kings Bay military base near Georgia suburban area\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the conversation with the AI\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Create 1-3 fictional characters\"}\n",
    "]\n",
    "\n",
    "# Define the expected response structure\n",
    "character_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"characters\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"characters\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"name\": {\"type\": \"string\"},\n",
    "                            \"occupation\": {\"type\": \"string\"},\n",
    "                            \"personality\": {\"type\": \"string\"},\n",
    "                            \"background\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"required\": [\"name\", \"occupation\", \"personality\", \"background\"]\n",
    "                    },\n",
    "                    \"minItems\": 1,\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"characters\"]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get response from AI\n",
    "response = client.chat.completions.create(\n",
    "    model=\"mlx-community/Qwen3-1.7B-4bit-DWQ\",\n",
    "    messages=messages,\n",
    "    response_format=character_schema,\n",
    ")\n",
    "\n",
    "# Parse and display the results\n",
    "results = json.loads(response.choices[0].message.content)\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0c3e851",
   "metadata": {},
   "source": [
    "## Tools (Function Calling)\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75ffdd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_b0b11d04', function=Function(arguments='{\"order_id\": \"order_12345\"}', name='get_delivery_date'), type='function')])\n",
      "[ChatCompletionMessageToolCall(id='call_b0b11d04', function=Function(arguments='{\"order_id\": \"order_12345\"}', name='get_delivery_date'), type='function')]\n",
      "ChatCompletionMessage(content=\"Your order's delivery date is December 11, 2024, at approximately 00:47:36. Thank you for your patience.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "model = \"mlx-community/Qwen3-1.7B-4bit-DWQ\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_delivery_date\",\n",
    "            \"description\": \"Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"order_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The customer's order ID.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"order_id\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi, can you tell me the delivery date for my order?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"Hi there! I can help with that. Can you please provide your order ID?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"i think it is order_12345\"\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "response_message = completion.choices[0].message\n",
    "print(response_message)\n",
    "print(response_message.tool_calls)\n",
    "\n",
    "messages.append(response_message)\n",
    "\n",
    "order_id = \"order_12345\"\n",
    "delivery_date = datetime.now()\n",
    "tool_call_id = response_message.tool_calls[0].id\n",
    "\n",
    "function_call_result_message = {\n",
    "    \"role\": \"tool\",\n",
    "    \"content\": json.dumps({\n",
    "        \"order_id\": order_id,\n",
    "        \"delivery_date\": delivery_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }),\n",
    "    \"tool_call_id\": tool_call_id\n",
    "}\n",
    "messages.append(function_call_result_message)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b6e3283",
   "metadata": {},
   "source": [
    "## logprobs\n",
    "\n",
    "[openai cookbook](https://cookbook.openai.com/examples/using_logprobs#1-using-logprobs-to-assess-confidence-for-classification-tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9c7f76d1-dea2-4b47-a669-2e06757f67e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"mlx-community/Qwen3-1.7B-4bit-DWQ\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ],\n",
    "  # stream=True,\n",
    "  logprobs=True,\n",
    "  top_logprobs=2, \n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c44dd4e-d947-4960-9448-6d8c78d6fa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-a4a5b3e89c', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.140625, top_logprobs=[TopLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.140625), TopLogprob(token='How', bytes=[72, 111, 119], logprob=-2.078125)]), ChatCompletionTokenLogprob(token='!', bytes=[33], logprob=-0.03125, top_logprobs=[TopLogprob(token='!', bytes=[33], logprob=-0.03125), TopLogprob(token='.', bytes=[46], logprob=-3.375)]), ChatCompletionTokenLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.71875, top_logprobs=[TopLogprob(token=' It', bytes=[32, 73, 116], logprob=-0.6875), TopLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.71875)]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=0.0, top_logprobs=[TopLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=0.0), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-7.859375)]), ChatCompletionTokenLogprob(token=' I', bytes=[32, 73], logprob=0.0, top_logprobs=[TopLogprob(token=' I', bytes=[32, 73], logprob=0.0), TopLogprob(token=' i', bytes=[32, 105], logprob=-12.484375)]), ChatCompletionTokenLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0625, top_logprobs=[TopLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0625), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-2.875)]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0, top_logprobs=[TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0), TopLogprob(token=' You', bytes=[32, 89, 111, 117], logprob=-13.640625)]), ChatCompletionTokenLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0, top_logprobs=[TopLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0), TopLogprob(token='?', bytes=[63], logprob=-11.5625)]), ChatCompletionTokenLogprob(token='?', bytes=[63], logprob=0.0, top_logprobs=[TopLogprob(token='?', bytes=[63], logprob=0.0), TopLogprob(token=',', bytes=[44], logprob=-10.921875)]), ChatCompletionTokenLogprob(token='<|eot_id|>', bytes=[60, 124, 101, 111, 116, 95, 105, 100, 124, 62], logprob=0.0, top_logprobs=[TopLogprob(token='<|eot_id|>', bytes=[60, 124, 101, 111, 116, 95, 105, 100, 124, 62], logprob=0.0), TopLogprob(token=' Do', bytes=[32, 68, 111], logprob=-5.9375)])], refusal=None), message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732542640, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=3, total_tokens=13, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f969c9f-44c3-4b2a-8257-62bb0fba7a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='Hello', logprob=-0.140625, bytes=[72, 101, 108, 108, 111], top_logprobs=[{'token': 'Hello', 'logprob': -0.140625, 'bytes': [72, 101, 108, 108, 111]}, {'token': 'How', 'logprob': -2.078125, 'bytes': [72, 111, 119]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='!', logprob=-0.03125, bytes=[33], top_logprobs=[{'token': '!', 'logprob': -0.03125, 'bytes': [33]}, {'token': '.', 'logprob': -3.375, 'bytes': [46]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='Hello!', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' It', logprob=-0.6875, bytes=[32, 73, 116], top_logprobs=[{'token': ' It', 'logprob': -0.6875, 'bytes': [32, 73, 116]}, {'token': ' How', 'logprob': -0.71875, 'bytes': [32, 72, 111, 119]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "Hello!\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=\"'s\", logprob=0.0, bytes=[39, 115], top_logprobs=[{'token': \"'s\", 'logprob': 0.0, 'bytes': [39, 115]}, {'token': ' seems', 'logprob': -11.0078125, 'bytes': [32, 115, 101, 101, 109, 115]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=\" It's\", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' nice', logprob=0.0, bytes=[32, 110, 105, 99, 101], top_logprobs=[{'token': ' nice', 'logprob': 0.0, 'bytes': [32, 110, 105, 99, 101]}, {'token': ' great', 'logprob': -6.953125, 'bytes': [32, 103, 114, 101, 97, 116]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " It's\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' nice', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' to', logprob=0.0, bytes=[32, 116, 111], top_logprobs=[{'token': ' to', 'logprob': 0.0, 'bytes': [32, 116, 111]}, {'token': ' of', 'logprob': -15.40625, 'bytes': [32, 111, 102]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " nice\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' meet', logprob=0.0, bytes=[32, 109, 101, 101, 116], top_logprobs=[{'token': ' meet', 'logprob': 0.0, 'bytes': [32, 109, 101, 101, 116]}, {'token': ' help', 'logprob': -5.28125, 'bytes': [32, 104, 101, 108, 112]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " to\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' meet', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' you', logprob=0.0, bytes=[32, 121, 111, 117], top_logprobs=[{'token': ' you', 'logprob': 0.0, 'bytes': [32, 121, 111, 117]}, {'token': ' You', 'logprob': -17.28125, 'bytes': [32, 89, 111, 117]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " meet\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='.', logprob=0.0, bytes=[46], top_logprobs=[{'token': '.', 'logprob': 0.0, 'bytes': [46]}, {'token': '!', 'logprob': -9.71875, 'bytes': [33]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' you.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' Is', logprob=-0.078125, bytes=[32, 73, 115], top_logprobs=[{'token': ' Is', 'logprob': -0.078125, 'bytes': [32, 73, 115]}, {'token': ' How', 'logprob': -2.703125, 'bytes': [32, 72, 111, 119]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " you.\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' Is', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' there', logprob=0.0, bytes=[32, 116, 104, 101, 114, 101], top_logprobs=[{'token': ' there', 'logprob': 0.0, 'bytes': [32, 116, 104, 101, 114, 101]}, {'token': ' There', 'logprob': -11.546875, 'bytes': [32, 84, 104, 101, 114, 101]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " Is\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' there', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' something', logprob=-0.296875, bytes=[32, 115, 111, 109, 101, 116, 104, 105, 110, 103], top_logprobs=[{'token': ' something', 'logprob': -0.296875, 'bytes': [32, 115, 111, 109, 101, 116, 104, 105, 110, 103]}, {'token': ' anything', 'logprob': -1.359375, 'bytes': [32, 97, 110, 121, 116, 104, 105, 110, 103]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " there\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' something', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' I', logprob=0.0, bytes=[32, 73], top_logprobs=[{'token': ' I', 'logprob': 0.0, 'bytes': [32, 73]}, {'token': ' specific', 'logprob': -6.421875, 'bytes': [32, 115, 112, 101, 99, 105, 102, 105, 99]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " something\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' can', logprob=0.0, bytes=[32, 99, 97, 110], top_logprobs=[{'token': ' can', 'logprob': 0.0, 'bytes': [32, 99, 97, 110]}, {'token': ' Can', 'logprob': -11.46875, 'bytes': [32, 67, 97, 110]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " I\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' help', logprob=-0.015625, bytes=[32, 104, 101, 108, 112], top_logprobs=[{'token': ' help', 'logprob': -0.015625, 'bytes': [32, 104, 101, 108, 112]}, {'token': ' assist', 'logprob': -4.046875, 'bytes': [32, 97, 115, 115, 105, 115, 116]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " can\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' you', logprob=0.0, bytes=[32, 121, 111, 117], top_logprobs=[{'token': ' you', 'logprob': 0.0, 'bytes': [32, 121, 111, 117]}, {'token': 'you', 'logprob': -12.625, 'bytes': [121, 111, 117]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " help\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' with', logprob=0.0, bytes=[32, 119, 105, 116, 104], top_logprobs=[{'token': ' with', 'logprob': 0.0, 'bytes': [32, 119, 105, 116, 104]}, {'token': 'with', 'logprob': -13.28125, 'bytes': [119, 105, 116, 104]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " you\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' or', logprob=-0.109375, bytes=[32, 111, 114], top_logprobs=[{'token': ' or', 'logprob': -0.109375, 'bytes': [32, 111, 114]}, {'token': ',', 'logprob': -2.4375, 'bytes': [44]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " with\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' or', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' would', logprob=0.0, bytes=[32, 119, 111, 117, 108, 100], top_logprobs=[{'token': ' would', 'logprob': 0.0, 'bytes': [32, 119, 111, 117, 108, 100]}, {'token': ' assist', 'logprob': -8.171875, 'bytes': [32, 97, 115, 115, 105, 115, 116]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " or\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' would', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' you', logprob=0.0, bytes=[32, 121, 111, 117], top_logprobs=[{'token': ' you', 'logprob': 0.0, 'bytes': [32, 121, 111, 117]}, {'token': ' You', 'logprob': -15.515625, 'bytes': [32, 89, 111, 117]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " would\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' like', logprob=0.0, bytes=[32, 108, 105, 107, 101], top_logprobs=[{'token': ' like', 'logprob': 0.0, 'bytes': [32, 108, 105, 107, 101]}, {'token': ' Like', 'logprob': -10.34375, 'bytes': [32, 76, 105, 107, 101]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " you\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' like', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' to', logprob=0.0, bytes=[32, 116, 111], top_logprobs=[{'token': ' to', 'logprob': 0.0, 'bytes': [32, 116, 111]}, {'token': ' some', 'logprob': -6.703125, 'bytes': [32, 115, 111, 109, 101]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " like\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' chat', logprob=-0.015625, bytes=[32, 99, 104, 97, 116], top_logprobs=[{'token': ' chat', 'logprob': -0.015625, 'bytes': [32, 99, 104, 97, 116]}, {'token': ' talk', 'logprob': -4.8125, 'bytes': [32, 116, 97, 108, 107]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      " to\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='?', logprob=-0.03125, bytes=[63], top_logprobs=[{'token': '?', 'logprob': -0.03125, 'bytes': [63]}, {'token': ' for', 'logprob': -3.796875, 'bytes': [32, 102, 111, 114]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n",
      "\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"mlx-community/Qwen3-1.7B-4bit-DWQ\",\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    logprobs=True,\n",
    "    top_logprobs=2, \n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk)\n",
    "    print(chunk.choices[0].delta.content)\n",
    "    print(\"****************\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "322e249e",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "```shell\n",
    "curl http://localhost:10240/v1/chat/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "  \"model\": \"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What'\\''s the weather like in Boston today?\"\n",
    "    }\n",
    "  ],\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"location\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"tool_choice\": \"auto\"\n",
    "}'\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708d3660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-5cd4a26f40', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='<|python_tag|><|python_tag|><|python_tag|><|python_tag|><|python_tag|>{\"name\":<|python_tag|>{\"name\":<|python_tag|>{\"name\":<|python_tag|>{\"name\":<|python_tag|>{\"name\":<|python_tag|>{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt.<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\"<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\".<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\".<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\".<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\".<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\".<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\",<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\":<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|><|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer.<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer.<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius,<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the unit<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the unit to<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the unit to<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the unit to<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the unit to<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the unit to \"celsius\".<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"celsius\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe temperature is not defined in the prompt. The unit can be set to either \"celsius\" or \"fahrenheit\". Let me provide an example using \"fahrenheit\". \\n\\n{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<|python_tag|>{\"name\": \"get_current_weather\", \"parameters\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}}<|eom_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nPlease note that you should look up the actual weather for Boston, MA to get the correct answer. \\n\\nIf you want to get the weather in Celsius, you can simply change the unit to \"celsius\".', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732598208, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=15106, prompt_tokens=2, total_tokens=15108, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "          },\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "      },\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    "  tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "print(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b69000c",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "api: https://platform.openai.com/docs/api-reference/models?lang=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b381640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='Locutusque/TinyMistral-248M', created=1718007710, object='model', owned_by='Locutusque', config={'architectures': ['MistralForCausalLM'], 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 1024, 'initializer_range': 0.02, 'intermediate_size': 4096, 'max_position_embeddings': 32768, 'model_type': 'mistral', 'num_attention_heads': 32, 'num_hidden_layers': 12, 'num_key_value_heads': 8, 'rms_norm_eps': 1e-06, 'rope_theta': 10000.0, 'sliding_window': 32, 'tie_word_embeddings': False, 'torch_dtype': 'float16', 'transformers_version': '4.35.0', 'use_cache': True, 'vocab_size': 32005}), Model(id='zeppdev/phi2-url', created=1706864758, object='model', owned_by='zeppdev', config={'vocab_size': 51200, 'hidden_size': 2560, 'intermediate_size': 10240, 'num_hidden_layers': 32, 'num_attention_heads': 32, 'num_key_value_heads': 32, 'resid_pdrop': 0.1, 'embd_pdrop': 0.0, 'attention_dropout': 0.0, 'hidden_act': 'gelu_new', 'max_position_embeddings': 2048, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'use_cache': True, 'rope_theta': 10000.0, 'rope_scaling': None, 'partial_rotary_factor': 0.4, 'qk_layernorm': False, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float16', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': False, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['PhiForCausalLM'], 'finetuning_task': None, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'phi2', 'transformers_version': '4.37.0', 'auto_map': {'AutoConfig': 'microsoft/phi-2--configuration_phi.PhiConfig', 'AutoModelForCausalLM': 'microsoft/phi-2--modeling_phi.PhiForCausalLM'}, 'model_type': 'phi', 'quantization': {'group_size': 64, 'bits': 4}}), Model(id='TinyLlama/TinyLlama-1.1B-Chat-v0.6', created=1703304187, object='model', owned_by='TinyLlama', config={'_name_or_path': '/mnt/petrelfs/libo1.p/alignment-handbook/data/tinyllama-2T-sft-full', 'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 5632, 'max_position_embeddings': 2048, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 22, 'num_key_value_heads': 4, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.35.0', 'use_cache': False, 'vocab_size': 32000}), Model(id='HuggingFaceTB/SmolLM2-1.7B-Instruct', created=1731393597, object='model', owned_by='HuggingFaceTB', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 8192, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 24, 'num_key_value_heads': 32, 'pad_token_id': 2, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 130000, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.42.3', 'transformers.js_config': {'kv_cache_dtype': {'q4f16': 'float16', 'fp16': 'float16'}}, 'use_cache': True, 'vocab_size': 49152}), Model(id='mlx-community/Meta-Llama-3.1-8B-Instruct-4bit', created=1732810644, object='model', owned_by='mlx-community', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': [128001, 128008, 128009], 'hidden_act': 'silu', 'hidden_size': 4096, 'initializer_range': 0.02, 'intermediate_size': 14336, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 8.0, 'low_freq_factor': 1.0, 'high_freq_factor': 4.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.42.3', 'use_cache': True, 'vocab_size': 128256}), Model(id='google/gemma-2b-it', created=1709813923, object='model', owned_by='google', config={'architectures': ['GemmaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 2, 'eos_token_id': 1, 'head_dim': 256, 'hidden_act': 'gelu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 16384, 'max_position_embeddings': 8192, 'model_type': 'gemma', 'num_attention_heads': 8, 'num_hidden_layers': 18, 'num_key_value_heads': 1, 'pad_token_id': 0, 'rms_norm_eps': 1e-06, 'rope_scaling': None, 'rope_theta': 10000.0, 'torch_dtype': 'bfloat16', 'transformers_version': '4.38.0.dev0', 'use_cache': True, 'vocab_size': 256000}), Model(id='mlx-community/Qwen2.5-3B-Instruct-4bit', created=1733719619, object='model', owned_by='mlx-community', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 11008, 'max_position_embeddings': 32768, 'max_window_layers': 70, 'model_type': 'qwen2', 'num_attention_heads': 16, 'num_hidden_layers': 36, 'num_key_value_heads': 2, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='microsoft/phi-1_5', created=1708791899, object='model', owned_by='microsoft', config={'_name_or_path': 'microsoft/phi-1_5', 'architectures': ['PhiForCausalLM'], 'auto_map': {'AutoConfig': 'configuration_phi.PhiConfig', 'AutoModelForCausalLM': 'modeling_phi.PhiForCausalLM'}, 'attention_dropout': 0.0, 'bos_token_id': None, 'embd_pdrop': 0.0, 'eos_token_id': None, 'hidden_act': 'gelu_new', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 8192, 'layer_norm_eps': 1e-05, 'max_position_embeddings': 2048, 'model_type': 'phi', 'num_attention_heads': 32, 'num_hidden_layers': 24, 'num_key_value_heads': None, 'partial_rotary_factor': 0.5, 'qk_layernorm': False, 'resid_pdrop': 0.0, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': False, 'torch_dtype': 'float16', 'transformers_version': '4.37.0', 'use_cache': True, 'vocab_size': 51200}), Model(id='mistralai/Mistral-7B-Instruct-v0.3', created=1726302222, object='model', owned_by='mistralai', config={'architectures': ['MistralForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 4096, 'initializer_range': 0.02, 'intermediate_size': 14336, 'max_position_embeddings': 32768, 'model_type': 'mistral', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 8, 'rms_norm_eps': 1e-05, 'rope_theta': 1000000.0, 'sliding_window': None, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.42.0.dev0', 'use_cache': True, 'vocab_size': 32768}), Model(id='FreedomIntelligence/Apollo-0.5B', created=1710154159, object='model', owned_by='FreedomIntelligence', config={'_name_or_path': '/223040239/medbase/ckpts/qwen0_5_allsft/checkpoint-0-18850/tfmr', 'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151643, 'hidden_act': 'silu', 'hidden_size': 1024, 'initializer_range': 0.02, 'intermediate_size': 2816, 'max_position_embeddings': 32768, 'max_window_layers': 21, 'model_type': 'qwen2', 'num_attention_heads': 16, 'num_hidden_layers': 24, 'num_key_value_heads': 16, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'float32', 'transformers_version': '4.38.2', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='madroid/Qwen2.5-0.5B-Instruct-mlx-4bit', created=1726734360, object='model', owned_by='madroid', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 896, 'initializer_range': 0.02, 'intermediate_size': 4864, 'max_position_embeddings': 32768, 'max_window_layers': 21, 'model_type': 'qwen2', 'num_attention_heads': 14, 'num_hidden_layers': 24, 'num_key_value_heads': 2, 'quantization': {'group_size': 64, 'bits': 4}, 'quantization_config': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='madroid/Qwen2.5-3B-Instruct-4bit-mlx', created=1733903275, object='model', owned_by='madroid', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 11008, 'max_position_embeddings': 32768, 'max_window_layers': 70, 'model_type': 'qwen2', 'num_attention_heads': 16, 'num_hidden_layers': 36, 'num_key_value_heads': 2, 'quantization': {'group_size': 64, 'bits': 4}, 'quantization_config': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='microsoft/Phi-3.5-mini-instruct-onnx', created=1730198719, object='model', owned_by='microsoft', config={'_name_or_path': 'Phi-3.5-mini-instruct', 'architectures': ['Phi3ForCausalLM'], 'attention_dropout': 0.0, 'auto_map': {'AutoConfig': 'configuration_phi3.Phi3Config', 'AutoModelForCausalLM': 'modeling_phi3.Phi3ForCausalLM'}, 'bos_token_id': 1, 'embd_pdrop': 0.0, 'eos_token_id': 32000, 'hidden_act': 'silu', 'hidden_size': 3072, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'model_type': 'phi3', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 32, 'original_max_position_embeddings': 4096, 'pad_token_id': 32000, 'resid_pdrop': 0.0, 'rms_norm_eps': 1e-05, 'rope_scaling': {'long_factor': [1.0800000429153442, 1.1100000143051147, 1.1399999856948853, 1.340000033378601, 1.5899999141693115, 1.600000023841858, 1.6200000047683716, 2.620000123977661, 3.2300000190734863, 3.2300000190734863, 4.789999961853027, 7.400000095367432, 7.700000286102295, 9.09000015258789, 12.199999809265137, 17.670000076293945, 24.46000099182129, 28.57000160217285, 30.420001983642578, 30.840002059936523, 32.590003967285156, 32.93000411987305, 42.320003509521484, 44.96000289916992, 50.340003967285156, 50.45000457763672, 57.55000305175781, 57.93000411987305, 58.21000289916992, 60.1400032043457, 62.61000442504883, 62.62000274658203, 62.71000289916992, 63.1400032043457, 63.1400032043457, 63.77000427246094, 63.93000411987305, 63.96000289916992, 63.970001220703125, 64.02999877929688, 64.06999969482422, 64.08000183105469, 64.12000274658203, 64.41000366210938, 64.4800033569336, 64.51000213623047, 64.52999877929688, 64.83999633789062], 'short_factor': [1.0, 1.0199999809265137, 1.0299999713897705, 1.0299999713897705, 1.0499999523162842, 1.0499999523162842, 1.0499999523162842, 1.0499999523162842, 1.0499999523162842, 1.0699999332427979, 1.0999999046325684, 1.1099998950958252, 1.1599998474121094, 1.1599998474121094, 1.1699998378753662, 1.2899998426437378, 1.339999794960022, 1.679999828338623, 1.7899998426437378, 1.8199998140335083, 1.8499997854232788, 1.8799997568130493, 1.9099997282028198, 1.9399996995925903, 1.9899996519088745, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0799996852874756, 2.0899996757507324, 2.189999580383301, 2.2199995517730713, 2.5899994373321533, 2.729999542236328, 2.749999523162842, 2.8399994373321533], 'type': 'longrope'}, 'rope_theta': 10000.0, 'sliding_window': 262144, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.3', 'use_cache': True, 'attention_bias': False, 'vocab_size': 32064}), Model(id='mlx-community/phi-2-dpo-7k', created=1706953381, object='model', owned_by='mlx-community', config={'_name_or_path': 'microsoft/phi-2', 'architectures': ['PhiForCausalLM'], 'auto_map': {'AutoConfig': 'configuration_phi.PhiConfig', 'AutoModelForCausalLM': 'modeling_phi.PhiForCausalLM'}, 'attention_dropout': 0.0, 'bos_token_id': 50256, 'embd_pdrop': 0.0, 'eos_token_id': 50256, 'hidden_act': 'gelu_new', 'hidden_size': 2560, 'initializer_range': 0.02, 'intermediate_size': 10240, 'layer_norm_eps': 1e-05, 'max_position_embeddings': 2048, 'model_type': 'phi', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 32, 'partial_rotary_factor': 0.4, 'qk_layernorm': False, 'resid_pdrop': 0.1, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': False, 'torch_dtype': 'float16', 'transformers_version': '4.37.0', 'use_cache': True, 'vocab_size': 51200}), Model(id='mlx-community/Mistral-Large-Instruct-2407-4bit', created=1721881831, object='model', owned_by='mlx-community', config={'architectures': ['MistralForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 12288, 'initializer_range': 0.02, 'intermediate_size': 28672, 'max_position_embeddings': 32768, 'model_type': 'mistral', 'num_attention_heads': 96, 'num_hidden_layers': 88, 'num_key_value_heads': 8, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_theta': 1000000.0, 'sliding_window': None, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.42.3', 'use_cache': True, 'vocab_size': 32768}), Model(id='nvidia/Nemotron-Mini-4B-Instruct', created=1734013702, object='model', owned_by='nvidia', config={'_name_or_path': 'nvidia/Minitron-4B-Instruct', 'architectures': ['NemotronForCausalLM'], 'bos_token_id': 2, 'eos_token_id': 3, 'hidden_act': 'relu2', 'hidden_size': 3072, 'initializer_range': 0.0134, 'intermediate_size': 9216, 'max_position_embeddings': 4096, 'model_type': 'nemotron', 'num_attention_heads': 24, 'num_hidden_layers': 32, 'num_key_value_heads': 8, 'norm_eps': 1e-05, 'rope_theta': 10000, 'partial_rotary_factor': 0.5, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.32.0.dev0', 'use_cache': True, 'vocab_size': 256000, 'kv_channels': 128}), Model(id='mlx-community/Llama-3.2-1B-Instruct-4bit', created=1727316450, object='model', owned_by='mlx-community', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': [128001, 128008, 128009], 'head_dim': 64, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 16, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'quantization': {'group_size': 64, 'bits': 4}, 'quantization_config': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.45.0.dev0', 'use_cache': True, 'vocab_size': 128256}), Model(id='Qwen/Qwen2.5-1.5B-Instruct', created=1729474728, object='model', owned_by='Qwen', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 1536, 'initializer_range': 0.02, 'intermediate_size': 8960, 'max_position_embeddings': 32768, 'max_window_layers': 21, 'model_type': 'qwen2', 'num_attention_heads': 12, 'num_hidden_layers': 28, 'num_key_value_heads': 2, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='Qwen/Qwen2-0.5B-Instruct-MLX', created=1734186121, object='model', owned_by='Qwen', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 896, 'initializer_range': 0.02, 'intermediate_size': 4864, 'max_position_embeddings': 32768, 'max_window_layers': 21, 'model_type': 'qwen2', 'num_attention_heads': 14, 'num_hidden_layers': 24, 'num_key_value_heads': 2, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.40.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='mlx-community/Qwen2.5-Coder-32B-Instruct-4bit', created=1731379169, object='model', owned_by='mlx-community', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 5120, 'initializer_range': 0.02, 'intermediate_size': 27648, 'max_position_embeddings': 32768, 'max_window_layers': 70, 'model_type': 'qwen2', 'num_attention_heads': 40, 'num_hidden_layers': 64, 'num_key_value_heads': 8, 'quantization': {'group_size': 64, 'bits': 4}, 'quantization_config': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 131072, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 152064}), Model(id='infly/OpenCoder-8B-Instruct', created=1731393599, object='model', owned_by='infly', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 96540, 'eos_token_id': 96539, 'hidden_act': 'silu', 'hidden_size': 4096, 'initializer_range': 0.02, 'intermediate_size': 14336, 'max_position_embeddings': 8192, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 500000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.37.0', 'use_cache': True, 'vocab_size': 96640}), Model(id='mlx-community/Qwen2.5-0.5B-Instruct-4bit', created=1726732523, object='model', owned_by='mlx-community', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 896, 'initializer_range': 0.02, 'intermediate_size': 4864, 'max_position_embeddings': 32768, 'max_window_layers': 21, 'model_type': 'qwen2', 'num_attention_heads': 14, 'num_hidden_layers': 24, 'num_key_value_heads': 2, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='mlx-community/QwQ-32B-Preview-4bit', created=1733125589, object='model', owned_by='mlx-community', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 5120, 'initializer_range': 0.02, 'intermediate_size': 27648, 'max_position_embeddings': 32768, 'max_window_layers': 64, 'model_type': 'qwen2', 'num_attention_heads': 40, 'num_hidden_layers': 64, 'num_key_value_heads': 8, 'quantization': {'group_size': 64, 'bits': 4}, 'quantization_config': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 152064}), Model(id='togethercomputer/RedPajama-INCITE-Chat-3B-v1', created=1685207489, object='model', owned_by='togethercomputer', config={'_name_or_path': '/root/fm/models/rp_3b_800b_real_fp16', 'architectures': ['GPTNeoXForCausalLM'], 'bos_token_id': 0, 'eos_token_id': 0, 'hidden_act': 'gelu', 'hidden_size': 2560, 'initializer_range': 0.02, 'intermediate_size': 10240, 'layer_norm_eps': 1e-05, 'max_position_embeddings': 2048, 'model_type': 'gpt_neox', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'rotary_emb_base': 10000, 'rotary_pct': 1.0, 'tie_word_embeddings': False, 'torch_dtype': 'float16', 'transformers_version': '4.28.1', 'use_cache': True, 'use_parallel_residual': False, 'vocab_size': 50432}), Model(id='mlx-community/c4ai-command-r-plus-4bit', created=1712290540, object='model', owned_by='mlx-community', config={'add_cross_attention': False, 'architectures': ['CohereForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bad_words_ids': None, 'begin_suppress_tokens': None, 'bos_token_id': 5, 'chunk_size_feed_forward': 0, 'cross_attention_hidden_size': None, 'decoder_start_token_id': None, 'diversity_penalty': 0.0, 'do_sample': False, 'early_stopping': False, 'encoder_no_repeat_ngram_size': 0, 'eos_token_id': 255001, 'exponential_decay_length_penalty': None, 'finetuning_task': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'hidden_act': 'silu', 'hidden_size': 12288, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'initializer_range': 0.02, 'intermediate_size': 33792, 'is_decoder': False, 'is_encoder_decoder': False, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'layer_norm_eps': 1e-05, 'length_penalty': 1.0, 'logit_scale': 0.8333333333333334, 'max_length': 20, 'max_position_embeddings': 8192, 'min_length': 0, 'model_max_length': 131072, 'model_type': 'cohere', 'no_repeat_ngram_size': 0, 'num_attention_heads': 96, 'num_beam_groups': 1, 'num_beams': 1, 'num_hidden_layers': 64, 'num_key_value_heads': 8, 'num_return_sequences': 1, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'pad_token_id': 0, 'prefix': None, 'problem_type': None, 'pruned_heads': {}, 'quantization': {'group_size': 64, 'bits': 4}, 'remove_invalid_values': False, 'repetition_penalty': 1.0, 'return_dict': True, 'return_dict_in_generate': False, 'rope_theta': 75000000.0, 'sep_token_id': None, 'suppress_tokens': None, 'task_specific_params': None, 'temperature': 1.0, 'tf_legacy_loss': False, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'tokenizer_class': None, 'top_k': 50, 'top_p': 1.0, 'torch_dtype': 'float16', 'torchscript': False, 'transformers_version': '4.39.3', 'typical_p': 1.0, 'use_bfloat16': False, 'use_cache': True, 'use_qk_norm': True, 'vocab_size': 256000}), Model(id='mlx-community/Qwen2.5-14B-Instruct-4bit', created=1730699918, object='model', owned_by='mlx-community', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 5120, 'initializer_range': 0.02, 'intermediate_size': 13824, 'max_position_embeddings': 32768, 'max_window_layers': 70, 'model_type': 'qwen2', 'num_attention_heads': 40, 'num_hidden_layers': 48, 'num_key_value_heads': 8, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 131072, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 152064}), Model(id='mlx-community/Octopus-v2-4bit', created=1712483039, object='model', owned_by='mlx-community', config={'add_cross_attention': False, 'architectures': ['GemmaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bad_words_ids': None, 'begin_suppress_tokens': None, 'bos_token_id': 2, 'chunk_size_feed_forward': 0, 'cross_attention_hidden_size': None, 'decoder_start_token_id': None, 'diversity_penalty': 0.0, 'do_sample': False, 'early_stopping': False, 'encoder_no_repeat_ngram_size': 0, 'eos_token_id': 1, 'exponential_decay_length_penalty': None, 'finetuning_task': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'head_dim': 256, 'hidden_act': 'gelu', 'hidden_activation': None, 'hidden_size': 2048, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'initializer_range': 0.02, 'intermediate_size': 16384, 'is_decoder': False, 'is_encoder_decoder': False, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'length_penalty': 1.0, 'max_length': 20, 'max_position_embeddings': 8192, 'min_length': 0, 'model_type': 'gemma', 'no_repeat_ngram_size': 0, 'num_attention_heads': 8, 'num_beam_groups': 1, 'num_beams': 1, 'num_hidden_layers': 18, 'num_key_value_heads': 1, 'num_return_sequences': 1, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'pad_token_id': 0, 'prefix': None, 'problem_type': None, 'pruned_heads': {}, 'remove_invalid_values': False, 'repetition_penalty': 1.0, 'return_dict': True, 'return_dict_in_generate': False, 'rms_norm_eps': 1e-06, 'rope_scaling': None, 'rope_theta': 10000.0, 'sep_token_id': None, 'suppress_tokens': None, 'task_specific_params': None, 'temperature': 1.0, 'tf_legacy_loss': False, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'tokenizer_class': None, 'top_k': 50, 'top_p': 1.0, 'torch_dtype': 'bfloat16', 'torchscript': False, 'transformers_version': '4.39.3', 'typical_p': 1.0, 'use_bfloat16': False, 'use_cache': True, 'vocab_size': 256022}), Model(id='g-ronimo/phi-2-OpenHermes-2.5', created=1707202517, object='model', owned_by='g-ronimo', config={'_name_or_path': 'microsoft/phi-2', 'architectures': ['PhiForCausalLM'], 'attention_dropout': 0.0, 'auto_map': {'AutoConfig': 'microsoft/phi-2--configuration_phi.PhiConfig', 'AutoModelForCausalLM': 'microsoft/phi-2--modeling_phi.PhiForCausalLM'}, 'bos_token_id': 50256, 'embd_pdrop': 0.0, 'eos_token_id': 50297, 'hidden_act': 'gelu_new', 'hidden_size': 2560, 'initializer_range': 0.02, 'intermediate_size': 10240, 'layer_norm_eps': 1e-05, 'max_position_embeddings': 2048, 'model_type': 'phi', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 32, 'partial_rotary_factor': 0.4, 'qk_layernorm': False, 'resid_pdrop': 0.1, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.37.2', 'use_cache': True, 'vocab_size': 51200}), Model(id='vilm/Quyen-SE-v0.1', created=1724206733, object='model', owned_by='vilm', config={'_name_or_path': 'vilm/Quyen-SE-v0.1', 'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 1024, 'initializer_range': 0.02, 'intermediate_size': 2816, 'max_position_embeddings': 32768, 'max_window_layers': 21, 'model_type': 'qwen2', 'num_attention_heads': 16, 'num_hidden_layers': 24, 'num_key_value_heads': 16, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 4096, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.38.1', 'use_cache': False, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='Qwen/Qwen2.5-0.5B-Instruct', created=1726731003, object='model', owned_by='Qwen', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 896, 'initializer_range': 0.02, 'intermediate_size': 4864, 'max_position_embeddings': 32768, 'max_window_layers': 21, 'model_type': 'qwen2', 'num_attention_heads': 14, 'num_hidden_layers': 24, 'num_key_value_heads': 2, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='HuggingFaceTB/SmolLM-360M-Instruct', created=1724737183, object='model', owned_by='HuggingFaceTB', config={'_name_or_path': 'HuggingFaceTB/SmolLM-360M', 'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 960, 'initializer_range': 0.02, 'intermediate_size': 2560, 'max_position_embeddings': 2048, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 15, 'num_hidden_layers': 32, 'num_key_value_heads': 5, 'pad_token_id': 2, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.42.3', 'use_cache': True, 'vocab_size': 49152}), Model(id='mlx-community/Mistral-7B-Instruct-v0.3-4bit', created=1720711171, object='model', owned_by='mlx-community', config={'architectures': ['MistralForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 4096, 'initializer_range': 0.02, 'intermediate_size': 14336, 'max_position_embeddings': 32768, 'model_type': 'mistral', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 8, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_theta': 1000000.0, 'sliding_window': None, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.42.0.dev0', 'use_cache': True, 'vocab_size': 32768}), Model(id='Qwen/Qwen2.5-Coder-7B-Instruct', created=1732642462, object='model', owned_by='Qwen', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 3584, 'initializer_range': 0.02, 'intermediate_size': 18944, 'max_position_embeddings': 32768, 'max_window_layers': 28, 'model_type': 'qwen2', 'num_attention_heads': 28, 'num_hidden_layers': 28, 'num_key_value_heads': 4, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 131072, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.44.0', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 152064}), Model(id='Qwen/Qwen2.5-3B-Instruct', created=1733890004, object='model', owned_by='Qwen', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 11008, 'max_position_embeddings': 32768, 'max_window_layers': 70, 'model_type': 'qwen2', 'num_attention_heads': 16, 'num_hidden_layers': 36, 'num_key_value_heads': 2, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 32768, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 151936}), Model(id='microsoft/Phi-3.5-mini-instruct', created=1730199185, object='model', owned_by='microsoft', config={'_name_or_path': 'Phi-3.5-mini-instruct', 'architectures': ['Phi3ForCausalLM'], 'attention_dropout': 0.0, 'auto_map': {'AutoConfig': 'configuration_phi3.Phi3Config', 'AutoModelForCausalLM': 'modeling_phi3.Phi3ForCausalLM'}, 'bos_token_id': 1, 'embd_pdrop': 0.0, 'eos_token_id': 32000, 'hidden_act': 'silu', 'hidden_size': 3072, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'model_type': 'phi3', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 32, 'original_max_position_embeddings': 4096, 'pad_token_id': 32000, 'resid_pdrop': 0.0, 'rms_norm_eps': 1e-05, 'rope_scaling': {'long_factor': [1.0800000429153442, 1.1100000143051147, 1.1399999856948853, 1.340000033378601, 1.5899999141693115, 1.600000023841858, 1.6200000047683716, 2.620000123977661, 3.2300000190734863, 3.2300000190734863, 4.789999961853027, 7.400000095367432, 7.700000286102295, 9.09000015258789, 12.199999809265137, 17.670000076293945, 24.46000099182129, 28.57000160217285, 30.420001983642578, 30.840002059936523, 32.590003967285156, 32.93000411987305, 42.320003509521484, 44.96000289916992, 50.340003967285156, 50.45000457763672, 57.55000305175781, 57.93000411987305, 58.21000289916992, 60.1400032043457, 62.61000442504883, 62.62000274658203, 62.71000289916992, 63.1400032043457, 63.1400032043457, 63.77000427246094, 63.93000411987305, 63.96000289916992, 63.970001220703125, 64.02999877929688, 64.06999969482422, 64.08000183105469, 64.12000274658203, 64.41000366210938, 64.4800033569336, 64.51000213623047, 64.52999877929688, 64.83999633789062], 'short_factor': [1.0, 1.0199999809265137, 1.0299999713897705, 1.0299999713897705, 1.0499999523162842, 1.0499999523162842, 1.0499999523162842, 1.0499999523162842, 1.0499999523162842, 1.0699999332427979, 1.0999999046325684, 1.1099998950958252, 1.1599998474121094, 1.1599998474121094, 1.1699998378753662, 1.2899998426437378, 1.339999794960022, 1.679999828338623, 1.7899998426437378, 1.8199998140335083, 1.8499997854232788, 1.8799997568130493, 1.9099997282028198, 1.9399996995925903, 1.9899996519088745, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0199997425079346, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0299997329711914, 2.0799996852874756, 2.0899996757507324, 2.189999580383301, 2.2199995517730713, 2.5899994373321533, 2.729999542236328, 2.749999523162842, 2.8399994373321533], 'type': 'longrope'}, 'rope_theta': 10000.0, 'sliding_window': 262144, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.3', 'use_cache': True, 'attention_bias': False, 'vocab_size': 32064}), Model(id='meta-llama/Llama-3.2-1B', created=1731393601, object='model', owned_by='meta-llama', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': 128001, 'head_dim': 64, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 16, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.45.0.dev0', 'use_cache': True, 'vocab_size': 128256}), Model(id='mlx-community/Mistral-Nemo-Instruct-2407-4bit', created=1721384168, object='model', owned_by='mlx-community', config={'architectures': ['MistralForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 1, 'eos_token_id': 2, 'head_dim': 128, 'hidden_act': 'silu', 'hidden_size': 5120, 'initializer_range': 0.02, 'intermediate_size': 14336, 'max_position_embeddings': 1024000, 'model_type': 'mistral', 'num_attention_heads': 32, 'num_hidden_layers': 40, 'num_key_value_heads': 8, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_theta': 1000000.0, 'sliding_window': None, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.0.dev0', 'use_cache': True, 'vocab_size': 131072}), Model(id='HuggingFaceTB/SmolLM-135M-Instruct', created=1724741648, object='model', owned_by='HuggingFaceTB', config={'_name_or_path': 'HuggingFaceTB/SmolLM-135M', 'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 576, 'initializer_range': 0.02, 'intermediate_size': 1536, 'max_position_embeddings': 2048, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 9, 'num_hidden_layers': 30, 'num_key_value_heads': 3, 'pad_token_id': 2, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.42.3', 'use_cache': True, 'vocab_size': 49152}), Model(id='microsoft/Phi-3-mini-128k-instruct', created=1718949924, object='model', owned_by='microsoft', config={'_name_or_path': 'Phi-3-mini-128k-instruct', 'architectures': ['Phi3ForCausalLM'], 'attention_dropout': 0.0, 'auto_map': {'AutoConfig': 'configuration_phi3.Phi3Config', 'AutoModelForCausalLM': 'modeling_phi3.Phi3ForCausalLM'}, 'bos_token_id': 1, 'embd_pdrop': 0.0, 'eos_token_id': 32000, 'hidden_act': 'silu', 'hidden_size': 3072, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'model_type': 'phi3', 'num_attention_heads': 32, 'num_hidden_layers': 32, 'num_key_value_heads': 32, 'original_max_position_embeddings': 4096, 'pad_token_id': 32000, 'resid_pdrop': 0.0, 'rms_norm_eps': 1e-05, 'rope_scaling': {'long_factor': [1.0299999713897705, 1.0499999523162842, 1.0499999523162842, 1.0799999237060547, 1.2299998998641968, 1.2299998998641968, 1.2999999523162842, 1.4499999284744263, 1.5999999046325684, 1.6499998569488525, 1.8999998569488525, 2.859999895095825, 3.68999981880188, 5.419999599456787, 5.489999771118164, 5.489999771118164, 9.09000015258789, 11.579999923706055, 15.65999984741211, 15.769999504089355, 15.789999961853027, 18.360000610351562, 21.989999771118164, 23.079999923706055, 30.009998321533203, 32.35000228881836, 32.590003967285156, 35.56000518798828, 39.95000457763672, 53.840003967285156, 56.20000457763672, 57.95000457763672, 59.29000473022461, 59.77000427246094, 59.920005798339844, 61.190006256103516, 61.96000671386719, 62.50000762939453, 63.3700065612793, 63.48000717163086, 63.48000717163086, 63.66000747680664, 63.850006103515625, 64.08000946044922, 64.760009765625, 64.80001068115234, 64.81001281738281, 64.81001281738281], 'short_factor': [1.05, 1.05, 1.05, 1.1, 1.1, 1.1500000000000001, 1.2000000000000002, 1.2500000000000002, 1.3000000000000003, 1.3500000000000003, 1.5000000000000004, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.000000000000001, 2.0500000000000007, 2.0500000000000007, 2.0500000000000007, 2.1000000000000005, 2.1000000000000005, 2.1000000000000005, 2.1500000000000004, 2.1500000000000004, 2.3499999999999996, 2.549999999999999, 2.5999999999999988, 2.5999999999999988, 2.7499999999999982, 2.849999999999998, 2.849999999999998, 2.9499999999999975], 'type': 'su'}, 'rope_theta': 10000.0, 'sliding_window': 262144, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.39.3', 'use_cache': True, 'vocab_size': 32064}), Model(id='mlx-community/dolphin-2_6-phi-2', created=1707065156, object='model', owned_by='mlx-community', config={'vocab_size': 51200, 'n_positions': 2048, 'n_embd': 2560, 'n_layer': 32, 'n_inner': None, 'n_head': 32, 'n_head_kv': None, 'rotary_dim': 32, 'activation_function': 'gelu_new', 'flash_attn': False, 'flash_rotary': False, 'fused_dense': False, 'attn_pdrop': 0.0, 'embd_pdrop': 0.0, 'resid_pdrop': 0.1, 'layer_norm_epsilon': 1e-05, 'initializer_range': 0.02, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float16', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': False, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['PhiForCausalLM'], 'finetuning_task': None, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'cognitivecomputations/dolphin-2_6-phi-2', 'transformers_version': '4.37.0', 'auto_map': {'AutoConfig': 'cognitivecomputations/dolphin-2_6-phi-2--configuration_phi.PhiConfig', 'AutoModelForCausalLM': 'cognitivecomputations/dolphin-2_6-phi-2--modeling_phi.PhiForCausalLM'}, 'img_processor': None, 'model_type': 'phi-msft', 'use_cache': False}), Model(id='mlx-community/Llama-3.2-3B-Instruct-4bit', created=1731581769, object='model', owned_by='mlx-community', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': [128001, 128008, 128009], 'head_dim': 128, 'hidden_act': 'silu', 'hidden_size': 3072, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 24, 'num_hidden_layers': 28, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'quantization': {'group_size': 64, 'bits': 4}, 'quantization_config': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.45.0.dev0', 'use_cache': True, 'vocab_size': 128256}), Model(id='meta-llama/Llama-3.2-3B-Instruct', created=1727577640, object='model', owned_by='meta-llama', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': [128001, 128008, 128009], 'head_dim': 128, 'hidden_act': 'silu', 'hidden_size': 3072, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 24, 'num_hidden_layers': 28, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.45.0.dev0', 'use_cache': True, 'vocab_size': 128256}), Model(id='google/gemma-2b', created=1709813878, object='model', owned_by='google', config={'architectures': ['GemmaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 2, 'eos_token_id': 1, 'head_dim': 256, 'hidden_act': 'gelu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 16384, 'max_position_embeddings': 8192, 'model_type': 'gemma', 'num_attention_heads': 8, 'num_hidden_layers': 18, 'num_key_value_heads': 1, 'pad_token_id': 0, 'rms_norm_eps': 1e-06, 'rope_scaling': None, 'rope_theta': 10000.0, 'torch_dtype': 'bfloat16', 'transformers_version': '4.38.0.dev0', 'use_cache': True, 'vocab_size': 256000}), Model(id='madroid/phi2-4bit-mlx', created=1708329879, object='model', owned_by='madroid', config={'vocab_size': 51200, 'hidden_size': 2560, 'intermediate_size': 10240, 'num_hidden_layers': 32, 'num_attention_heads': 32, 'num_key_value_heads': 32, 'resid_pdrop': 0.1, 'embd_pdrop': 0.0, 'attention_dropout': 0.0, 'hidden_act': 'gelu_new', 'max_position_embeddings': 2048, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'use_cache': True, 'rope_theta': 10000.0, 'rope_scaling': None, 'partial_rotary_factor': 0.4, 'qk_layernorm': False, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float16', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': False, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['PhiForCausalLM'], 'finetuning_task': None, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 50256, 'pad_token_id': None, 'eos_token_id': 50256, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '/Users/madroid/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670', 'transformers_version': '4.37.2', 'auto_map': {'AutoConfig': 'configuration_phi.PhiConfig', 'AutoModelForCausalLM': 'modeling_phi.PhiForCausalLM'}, 'model_type': 'phi', 'quantization': {'group_size': 64, 'bits': 4}}), Model(id='mlx-community/Llama-3.3-70B-Instruct-4bit', created=1733544983, object='model', owned_by='mlx-community', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': [128001, 128008, 128009], 'head_dim': 128, 'hidden_act': 'silu', 'hidden_size': 8192, 'initializer_range': 0.02, 'intermediate_size': 28672, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 64, 'num_hidden_layers': 80, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'quantization': {'group_size': 64, 'bits': 4}, 'quantization_config': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 8.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.47.0.dev0', 'use_cache': True, 'vocab_size': 128256}), Model(id='nvidia/Llama-3.1-Nemotron-70B-Instruct-HF', created=1731393598, object='model', owned_by='nvidia', config={'_name_or_path': 'meta-llama/Llama-3.1-70B-Instruct', 'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': [128001, 128008, 128009], 'head_dim': 128, 'hidden_act': 'silu', 'hidden_size': 8192, 'initializer_range': 0.02, 'intermediate_size': 28672, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 64, 'num_hidden_layers': 80, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 8.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.40.0', 'use_cache': True, 'vocab_size': 128256}), Model(id='tablegpt/TableGPT2-7B', created=1731393603, object='model', owned_by='tablegpt', config={'_name_or_path': 'Qwen/Qwen2.5-7B-Instruct', 'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 3584, 'initializer_range': 0.02, 'intermediate_size': 18944, 'max_position_embeddings': 32768, 'max_window_layers': 28, 'model_type': 'qwen2', 'num_attention_heads': 28, 'num_hidden_layers': 28, 'num_key_value_heads': 4, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': None, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.44.2', 'use_cache': False, 'use_sliding_window': False, 'vocab_size': 152064}), Model(id='Qwen/Qwen2.5-Coder-32B-Instruct', created=1732811355, object='model', owned_by='Qwen', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 5120, 'initializer_range': 0.02, 'intermediate_size': 27648, 'max_position_embeddings': 32768, 'max_window_layers': 70, 'model_type': 'qwen2', 'num_attention_heads': 40, 'num_hidden_layers': 64, 'num_key_value_heads': 8, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 131072, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 152064}), Model(id='mlx-community/Qwen2.5-32B-Instruct-4bit', created=1730804686, object='model', owned_by='mlx-community', config={'architectures': ['Qwen2ForCausalLM'], 'attention_dropout': 0.0, 'bos_token_id': 151643, 'eos_token_id': 151645, 'hidden_act': 'silu', 'hidden_size': 5120, 'initializer_range': 0.02, 'intermediate_size': 27648, 'max_position_embeddings': 32768, 'max_window_layers': 70, 'model_type': 'qwen2', 'num_attention_heads': 40, 'num_hidden_layers': 64, 'num_key_value_heads': 8, 'quantization': {'group_size': 64, 'bits': 4}, 'rms_norm_eps': 1e-06, 'rope_theta': 1000000.0, 'sliding_window': 131072, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.43.1', 'use_cache': True, 'use_sliding_window': False, 'vocab_size': 152064}), Model(id='TinyLlama/TinyLlama-1.1B-Chat-v1.0', created=1705240329, object='model', owned_by='TinyLlama', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'bos_token_id': 1, 'eos_token_id': 2, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 5632, 'max_position_embeddings': 2048, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 22, 'num_key_value_heads': 4, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': None, 'rope_theta': 10000.0, 'tie_word_embeddings': False, 'torch_dtype': 'bfloat16', 'transformers_version': '4.35.0', 'use_cache': True, 'vocab_size': 32000}), Model(id='meta-llama/Llama-3.2-1B-Instruct', created=1727576405, object='model', owned_by='meta-llama', config={'architectures': ['LlamaForCausalLM'], 'attention_bias': False, 'attention_dropout': 0.0, 'bos_token_id': 128000, 'eos_token_id': [128001, 128008, 128009], 'head_dim': 64, 'hidden_act': 'silu', 'hidden_size': 2048, 'initializer_range': 0.02, 'intermediate_size': 8192, 'max_position_embeddings': 131072, 'mlp_bias': False, 'model_type': 'llama', 'num_attention_heads': 32, 'num_hidden_layers': 16, 'num_key_value_heads': 8, 'pretraining_tp': 1, 'rms_norm_eps': 1e-05, 'rope_scaling': {'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'rope_theta': 500000.0, 'tie_word_embeddings': True, 'torch_dtype': 'bfloat16', 'transformers_version': '4.45.0.dev0', 'use_cache': True, 'vocab_size': 128256})], object='list')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
